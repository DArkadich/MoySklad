#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ MoySklad –≤–Ω—É—Ç—Ä–∏ Docker –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞
"""

import asyncio
import httpx
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import json
import logging
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
import pickle
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MoySkladDataCollector:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ MoySklad API"""
    
    def __init__(self):
        self.api_token = os.getenv('MOYSKLAD_API_TOKEN')
        self.api_url = os.getenv('MOYSKLAD_API_URL', 'https://api.moysklad.ru/api/remap/1.2')
        
        if not self.api_token:
            raise ValueError("MOYSKLAD_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        
        self.headers = {
            "Authorization": f"Bearer {self.api_token}",
            "Content-Type": "application/json"
        }
    
    async def get_all_products(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ MoySklad"""
        try:
            async with httpx.AsyncClient() as client:
                response = await client.get(
                    f"{self.api_url}/entity/product",
                    headers=self.headers,
                    timeout=30.0
                )
                
                if response.status_code == 200:
                    data = response.json()
                    products = data.get("rows", [])
                    logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –∏–∑ MoySklad")
                    return products
                else:
                    logger.error(f"–û—à–∏–±–∫–∞ API MoySklad: {response.status_code} - {response.text}")
                    return []
                    
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤: {e}")
            return []
    
    async def get_sales_data(self, product_id: str, days_back: int = 180) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö —Ç–æ–≤–∞—Ä–∞"""
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days_back)
            
            async with httpx.AsyncClient() as client:
                # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø—Ä–æ–¥–∞–∂
                response = await client.get(
                    f"{self.api_url}/entity/demand",
                    headers=self.headers,
                    params={
                        "filter": f"moment>={start_date.isoformat()},moment<={end_date.isoformat()}",
                        "limit": 1000
                    },
                    timeout=30.0
                )
                
                if response.status_code != 200:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –ø—Ä–æ–¥–∞–∂: {response.status_code}")
                    return []
                
                data = response.json()
                sales_data = []
                
                for demand in data.get("rows", []):
                    # –ü–æ–ª—É—á–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞
                    positions_response = await client.get(
                        f"{self.api_url}/entity/demand/{demand['id']}/positions",
                        headers=self.headers,
                        timeout=30.0
                    )
                    
                    if positions_response.status_code == 200:
                        positions_data = positions_response.json()
                        
                        for position in positions_data.get("rows", []):
                            if position["assortment"]["id"] == product_id:
                                sales_data.append({
                                    "date": demand["moment"],
                                    "quantity": position["quantity"],
                                    "price": position["price"] / 100,  # –¶–µ–Ω–∞ –∏–∑ –∫–æ–ø–µ–µ–∫
                                    "sum": position["sum"] / 100
                                })
                
                logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(sales_data)} –∑–∞–ø–∏—Å–µ–π –ø—Ä–æ–¥–∞–∂ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id}")
                return sales_data
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –¥–ª—è {product_id}: {e}")
            return []
    
    async def get_stock_data(self, product_id: str, days_back: int = 30) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö —Ç–æ–≤–∞—Ä–∞"""
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=days_back)
            
            async with httpx.AsyncClient() as client:
                # –ü–æ–ª—É—á–∞–µ–º –æ—Ç—á–µ—Ç –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö
                response = await client.get(
                    f"{self.api_url}/report/stock/all",
                    headers=self.headers,
                    params={
                        "filter": f"assortmentId={product_id}",
                        "momentFrom": start_date.isoformat(),
                        "momentTo": end_date.isoformat()
                    },
                    timeout=30.0
                )
                
                if response.status_code != 200:
                    logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Å—Ç–∞—Ç–∫–æ–≤: {response.status_code}")
                    return []
                
                data = response.json()
                stock_data = []
                
                for row in data.get("rows", []):
                    stock_data.append({
                        "date": row.get("moment", datetime.now().isoformat()),
                        "quantity": row.get("quantity", 0),
                        "reserve": row.get("reserve", 0),
                        "inTransit": row.get("inTransit", 0)
                    })
                
                logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(stock_data)} –∑–∞–ø–∏—Å–µ–π –æ—Å—Ç–∞—Ç–∫–æ–≤ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id}")
                return stock_data
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö –¥–ª—è {product_id}: {e}")
            return []

class MLModelTrainer:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self):
        self.models_dir = "data/real_models"
        os.makedirs(self.models_dir, exist_ok=True)
    
    def prepare_features(self, sales_data: List[Dict], stock_data: List[Dict]) -> pd.DataFrame:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        if not sales_data:
            return pd.DataFrame()
        
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö
        df = pd.DataFrame(sales_data)
        df['date'] = pd.to_datetime(df['date'])
        df = df.set_index('date').sort_index()
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –¥–Ω—è–º
        daily_sales = df.groupby(df.index.date).agg({
            'quantity': 'sum',
            'price': 'mean',
            'sum': 'sum'
        }).reset_index()
        daily_sales['date'] = pd.to_datetime(daily_sales['date'])
        daily_sales = daily_sales.set_index('date')
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        daily_sales['year'] = daily_sales.index.year
        daily_sales['month'] = daily_sales.index.month
        daily_sales['day'] = daily_sales.index.day
        daily_sales['day_of_year'] = daily_sales.index.dayofyear
        daily_sales['day_of_week'] = daily_sales.index.dayofweek
        daily_sales['is_month_start'] = daily_sales.index.day == 1
        daily_sales['is_quarter_start'] = (daily_sales.index.day == 1) & (daily_sales.index.month.isin([1, 4, 7, 10]))
        daily_sales['is_weekend'] = daily_sales.index.dayofweek >= 5
        
        # –°–µ–∑–æ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        daily_sales['is_holiday_season'] = daily_sales.index.month.isin([12, 1, 2])
        daily_sales['is_summer_season'] = daily_sales.index.month.isin([6, 7, 8])
        
        # –õ–∞–≥–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        daily_sales['quantity_lag_1'] = daily_sales['quantity'].shift(1)
        daily_sales['quantity_lag_7'] = daily_sales['quantity'].shift(7)
        daily_sales['quantity_lag_30'] = daily_sales['quantity'].shift(30)
        
        # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
        daily_sales['quantity_ma_7'] = daily_sales['quantity'].rolling(7).mean()
        daily_sales['quantity_ma_30'] = daily_sales['quantity'].rolling(30).mean()
        
        # –£–¥–∞–ª—è–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
        daily_sales = daily_sales.dropna()
        
        return daily_sales
    
    def train_models(self, product_id: str, features_df: pd.DataFrame) -> Dict:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
        if len(features_df) < 30:
            logger.warning(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id}: {len(features_df)} –∑–∞–ø–∏—Å–µ–π")
            return {}
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        feature_columns = [col for col in features_df.columns if col not in ['quantity', 'price', 'sum']]
        X = features_df[feature_columns].values
        y = features_df['quantity'].values
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        models = {}
        
        # –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
        lr_model = LinearRegression()
        lr_model.fit(X_train_scaled, y_train)
        lr_score = lr_model.score(X_test_scaled, y_test)
        models['linear_regression'] = {
            'model': lr_model,
            'scaler': scaler,
            'accuracy': lr_score,
            'feature_columns': feature_columns
        }
        
        # –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
        rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
        rf_model.fit(X_train_scaled, y_train)
        rf_score = rf_model.score(X_test_scaled, y_test)
        models['random_forest'] = {
            'model': rf_model,
            'scaler': scaler,
            'accuracy': rf_score,
            'feature_columns': feature_columns
        }
        
        logger.info(f"–ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id} –æ–±—É—á–µ–Ω—ã:")
        logger.info(f"  Linear Regression: {lr_score:.4f}")
        logger.info(f"  Random Forest: {rf_score:.4f}")
        
        return models
    
    def save_models(self, product_id: str, models: Dict):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
        model_data = {
            'product_id': product_id,
            'models': {},
            'results': {},
            'features': [],
            'training_date': datetime.now().isoformat(),
            'model_type': 'real_data'
        }
        
        for model_name, model_info in models.items():
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            model_path = os.path.join(self.models_dir, f"{product_id}_{model_name}.pkl")
            with open(model_path, 'wb') as f:
                pickle.dump(model_info['model'], f)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º scaler
            scaler_path = os.path.join(self.models_dir, f"{product_id}_{model_name}_scaler.pkl")
            with open(scaler_path, 'wb') as f:
                pickle.dump(model_info['scaler'], f)
            
            model_data['models'][model_name] = model_path
            model_data['results'][model_name] = {
                'accuracy': model_info['accuracy'],
                'feature_columns': model_info['feature_columns']
            }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata_path = os.path.join(self.models_dir, f"{product_id}_metadata.json")
        with open(metadata_path, 'w') as f:
            json.dump(model_data, f, indent=2)
        
        logger.info(f"–ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {self.models_dir}")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ MoySklad (–≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ)")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    data_collector = MoySkladDataCollector()
    model_trainer = MLModelTrainer()
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
    products = await data_collector.get_all_products()
    
    if not products:
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–≤–∞—Ä—ã –∏–∑ MoySklad")
        return
    
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_products = products[:5]  # –ü–µ—Ä–≤—ã–µ 5 —Ç–æ–≤–∞—Ä–æ–≤
    
    for product in test_products:
        product_id = product['id']
        product_name = product.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä')
        product_code = product.get('code', '')
        
        logger.info(f"üì¶ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä: {product_name} (ID: {product_id}, –ö–æ–¥: {product_code})")
        
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö
            sales_data = await data_collector.get_sales_data(product_id, days_back=180)
            
            if not sales_data:
                logger.warning(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_name}")
                continue
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö
            stock_data = await data_collector.get_stock_data(product_id, days_back=30)
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            features_df = model_trainer.prepare_features(sales_data, stock_data)
            
            if features_df.empty:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_name}")
                continue
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            models = model_trainer.train_models(product_id, features_df)
            
            if models:
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
                model_trainer.save_models(product_id, models)
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_name} —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
            else:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_name}")
        
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞ {product_name}: {e}")
            continue
    
    logger.info("üéâ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    asyncio.run(main()) 