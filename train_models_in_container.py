#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.
–ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç ‚Äî –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É —Å –æ—à–∏–±–∫–æ–π.
"""

import os
import sys
import logging
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
import joblib

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ContainerModelTrainer:
    """–¢—Ä–µ–Ω–∏—Ä–æ–≤—â–∏–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è —Ä–∞–±–æ—Ç—ã —Ç–æ–ª—å–∫–æ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    
    def __init__(self):
        self.models_dir = "/app/data/models"
        try:
            os.makedirs(self.models_dir, exist_ok=True)
        except PermissionError:
            self.models_dir = "/tmp/models"
            os.makedirs(self.models_dir, exist_ok=True)
            logger.info(f"üìÅ –ú–æ–¥–µ–ª–∏ –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {self.models_dir}")

    def load_real_historical_data(self, data_dir):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ"""
        logger.info("üìä –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
        production_data_file = os.path.join(data_dir, 'production_stock_data.csv')
        if os.path.exists(production_data_file):
            try:
                data = pd.read_csv(production_data_file)
                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –∏–∑ production_stock_data.csv")
                products = data['product_code'].unique() if 'product_code' in data.columns else []
                logger.info(f"üì¶ –ù–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤")
                return data, products
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ production_stock_data.csv: {e}")
                return None, []
        else:
            logger.error("‚ùå –ù–µ—Ç —Ñ–∞–π–ª–∞ production_stock_data.csv! –û–±—É—á–µ–Ω–∏–µ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ.")
            return None, []

    def prepare_features_from_real_data(self, real_data):
        logger.info("üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        if 'date' in real_data.columns:
            real_data['date'] = pd.to_datetime(real_data['date'])
            real_data['year'] = real_data['date'].dt.year
            real_data['month'] = real_data['date'].dt.month
            real_data['day_of_week'] = real_data['date'].dt.dayofweek
            real_data['day_of_year'] = real_data['date'].dt.dayofyear
        if 'quantity' not in real_data.columns:
            logger.error('‚ùå –ù–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ quantity –≤ –¥–∞–Ω–Ω—ã—Ö!')
            raise ValueError('–ù–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ quantity –≤ –¥–∞–Ω–Ω—ã—Ö!')
        if 'stock' not in real_data.columns:
            logger.error('‚ùå –ù–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ stock –≤ –¥–∞–Ω–Ω—ã—Ö!')
            raise ValueError('–ù–µ—Ç –∫–æ–ª–æ–Ω–∫–∏ stock –≤ –¥–∞–Ω–Ω—ã—Ö!')
        if 'product_code' in real_data.columns:
            for lag in [1, 7, 30]:
                real_data[f'quantity_lag_{lag}'] = real_data.groupby('product_code')['quantity'].shift(lag)
                real_data[f'stock_lag_{lag}'] = real_data.groupby('product_code')['stock'].shift(lag)
            for window in [7, 30]:
                real_data[f'quantity_ma_{window}'] = real_data.groupby('product_code')['quantity'].rolling(window).mean().reset_index(0, drop=True)
                real_data[f'stock_ma_{window}'] = real_data.groupby('product_code')['stock'].rolling(window).mean().reset_index(0, drop=True)
            real_data['quantity_std_30'] = real_data.groupby('product_code')['quantity'].rolling(30).std().reset_index(0, drop=True)
            real_data['stock_std_30'] = real_data.groupby('product_code')['stock'].rolling(30).std().reset_index(0, drop=True)
        real_data = real_data.dropna()
        logger.info(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(real_data)} –∑–∞–ø–∏—Å–µ–π —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
        return real_data

    def train_model_for_product(self, product_data, product_code):
        logger.info(f"üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_code}...")
        base_features = ['year', 'month', 'day_of_week', 'day_of_year']
        lag_features = []
        ma_features = []
        std_features = []
        for lag in [1, 7, 30]:
            if f'stock_lag_{lag}' in product_data.columns:
                lag_features.append(f'stock_lag_{lag}')
            if f'quantity_lag_{lag}' in product_data.columns:
                lag_features.append(f'quantity_lag_{lag}')
        for window in [7, 30]:
            if f'stock_ma_{window}' in product_data.columns:
                ma_features.append(f'stock_ma_{window}')
            if f'quantity_ma_{window}' in product_data.columns:
                ma_features.append(f'quantity_ma_{window}')
        if 'stock_std_30' in product_data.columns:
            std_features.append('stock_std_30')
        if 'quantity_std_30' in product_data.columns:
            std_features.append('quantity_std_30')
        feature_columns = base_features + lag_features + ma_features + std_features
        X = product_data[feature_columns]
        y = product_data['quantity']
        model = RandomForestRegressor(n_estimators=200, random_state=42)
        model.fit(X, y)
        model_path = os.path.join(self.models_dir, f"{product_code}_model.joblib")
        joblib.dump(model, model_path)
        scaler = StandardScaler()
        scaler.fit(X)
        scaler_path = os.path.join(self.models_dir, f"{product_code}_scaler.joblib")
        joblib.dump(scaler, scaler_path)
        logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –¥–ª—è {product_code} —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞")
        return model_path

    def train_all_models(self):
        logger.info("üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π...")
        data_dir = '/app/data'
        try:
            os.makedirs(data_dir, exist_ok=True)
        except PermissionError:
            data_dir = '/tmp/data'
            os.makedirs(data_dir, exist_ok=True)
            logger.info(f"üìÅ –î–∞–Ω–Ω—ã–µ –±—É–¥—É—Ç –∏—Å–∫–∞—Ç—å—Å—è –≤ {data_dir}")
        real_data, real_products = self.load_real_historical_data(data_dir)
        if real_data is None or len(real_products) == 0:
            logger.error("‚ùå –ù–µ—Ç —Ä–µ–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è! –ó–∞–≤–µ—Ä—à–∞–µ–º —Ä–∞–±–æ—Ç—É.")
            sys.exit(1)
        logger.info("üéØ –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ")
        data = self.prepare_features_from_real_data(real_data)
        trained_models = []
        for product_code in real_products:
            product_data = data[data['product_code'] == product_code]
            if len(product_data) > 100:
                model_path = self.train_model_for_product(product_data, product_code)
                trained_models.append(model_path)
        logger.info(f"‚úÖ –û–±—É—á–µ–Ω–æ {len(trained_models)} –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö")
        return trained_models

def main():
    logger.info("üéØ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–µ...")
    try:
        trainer = ContainerModelTrainer()
        trained_models = trainer.train_all_models()
        logger.info("üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
        logger.info(f"üìä –û–±—É—á–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {len(trained_models)}")
        logger.info("üîÑ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 