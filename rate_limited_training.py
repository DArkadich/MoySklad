#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π API MoySklad
"""

import asyncio
import httpx
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
import json
import logging
import time
import random
from collections import deque
import random
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
import pickle
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RateLimitedMoySkladCollector:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ MoySklad API —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π"""
    
    def __init__(self):
        self.api_token = os.getenv('MOYSKLAD_API_TOKEN')
        self.api_url = os.getenv('MOYSKLAD_API_URL', 'https://api.moysklad.ru/api/remap/1.2')
        
        if not self.api_token:
            raise ValueError("MOYSKLAD_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        
        self.headers = {
            "Authorization": f"Bearer {self.api_token}",
            "Content-Type": "application/json"
        }
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è API
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–∏–º–∏—Ç–æ–≤: —Ü–µ–ª–∏–º—Å—è –Ω–∏–∂–µ 200 req/min –¥–ª—è –∑–∞–ø–∞—Å–∞
        self.requests_per_minute = int(os.getenv('MSK_REQ_PER_MIN', '180'))
        self.min_delay_between_requests = float(os.getenv('MSK_MIN_DELAY_SEC', '0.30'))
        self.last_request_time = 0.0
        self.request_timestamps = deque()  # –º–æ–º–µ–Ω—Ç—ã –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ (—Å–µ–∫—É–Ω–¥—ã)
        
    async def _rate_limit(self):
        """–°–∫–æ–ª—å–∑—è—â–µ–µ –æ–∫–Ω–æ: –Ω–µ –±–æ–ª–µ–µ N –∑–∞–ø—Ä–æ—Å–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 60 —Å–µ–∫—É–Ω–¥ + –º–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ —Å –¥–∂–∏—Ç—Ç–µ—Ä–æ–º."""
        now = time.time()
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        since_last = now - self.last_request_time
        if since_last < self.min_delay_between_requests:
            sleep_time = self.min_delay_between_requests - since_last + random.uniform(0.02, 0.12)
            await asyncio.sleep(sleep_time)
            now = time.time()

        # –ß–∏—Å—Ç–∏–º –æ–∫–Ω–æ —Å—Ç–∞—Ä—à–µ 60 —Å–µ–∫—É–Ω–¥
        while self.request_timestamps and now - self.request_timestamps[0] > 60.0:
            self.request_timestamps.popleft()

        # –ï—Å–ª–∏ –¥–æ—Å—Ç–∏–≥–ª–∏ –ª–∏–º–∏—Ç–∞, –∂–¥—ë–º –¥–æ –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏—è –æ–∫–Ω–∞
        if len(self.request_timestamps) >= self.requests_per_minute:
            sleep_needed = 60.0 - (now - self.request_timestamps[0]) + random.uniform(0.05, 0.15)
            logger.info(f"‚è≥ –î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç {self.requests_per_minute}/–º–∏–Ω. –û–∂–∏–¥–∞–Ω–∏–µ {sleep_needed:.1f} c...")
            await asyncio.sleep(max(0.0, sleep_needed))

        # –§–∏–∫—Å–∏—Ä—É–µ–º —Ç–µ–∫—É—â–∏–π –∑–∞–ø—Ä–æ—Å
        self.last_request_time = time.time()
        self.request_timestamps.append(self.last_request_time)
    
    async def _make_request(self, method: str, url: str, **kwargs) -> Optional[Dict]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏"""
        await self._rate_limit()
        
        try:
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.request(method, url, headers=self.headers, **kwargs)
                
                if response.status_code == 200:
                    return response.json()
                elif response.status_code in (429, 412):  # Rate-limit / anti-bot
                    logger.warning(f"‚ö†Ô∏è –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ API ({response.status_code}). –û–∂–∏–¥–∞–Ω–∏–µ 60 —Å–µ–∫—É–Ω–¥...")
                    await asyncio.sleep(60)
                    return None
                elif response.status_code == 403:  # Forbidden
                    logger.error("‚ùå API –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ç–æ–∫–µ–Ω –∏ –ø—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø–∞.")
                    return None
                else:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ API: {response.status_code} - {response.text}")
                    return None
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return None
    
    async def get_all_products(self) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–∞ (—Å –∫–æ–¥–∞–º–∏) –∏–∑ MoySklad —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏"""
        logger.info("üì¶ –ü–æ–ª—É—á–µ–Ω–∏–µ –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–∞ –∏–∑ MoySklad...")
        all_rows: List[Dict] = []
        offset = 0
        page_size = 100
        while True:
            data = await self._make_request(
                "GET",
                f"{self.api_url}/entity/assortment",
                params={"limit": page_size, "offset": offset},
            )
            if not data:
                break
            rows = data.get("rows", [])
            if not rows:
                break
            all_rows.extend(rows)
            if len(rows) < page_size:
                break
            offset += page_size
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(all_rows)} –ø–æ–∑–∏—Ü–∏–π –∞—Å—Å–æ—Ä—Ç–∏–º–µ–Ω—Ç–∞ –∏–∑ MoySklad")
        return all_rows
    
    async def get_sales_data(self, product_id: str, days_back: int = 90) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö —Ç–æ–≤–∞—Ä–∞ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏"""
        logger.info(f"üìä –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–¥–∞–∂–∞—Ö –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id}...")

        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)

        # –§–æ—Ä–º–∞—Ç –¥–∞—Ç –±–µ–∑ –º–∏–∫—Ä–æ—Å–µ–∫—É–Ω–¥ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å API
        moment_from = start_date.replace(microsecond=0).strftime('%Y-%m-%dT00:00:00')
        moment_to = end_date.replace(microsecond=0).strftime('%Y-%m-%dT23:59:59')

        # –ü–æ–ª—É—á–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø—Ä–æ–¥–∞–∂ —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º momentFrom/momentTo)
        data = await self._make_request(
            "GET",
            f"{self.api_url}/entity/demand",
            params={
                "momentFrom": moment_from,
                "momentTo": moment_to,
                "limit": 100  # –£–º–µ–Ω—å—à–∞–µ–º –ª–∏–º–∏—Ç
            }
        )
        
        if not data:
            return []
        
        sales_data = []
        
        for demand in data.get("rows", []):
            # –ü–æ–ª—É—á–∞–µ–º –ø–æ–∑–∏—Ü–∏–∏ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å –∑–∞–¥–µ—Ä–∂–∫–æ–π
            positions_data = await self._make_request(
                "GET",
                f"{self.api_url}/entity/demand/{demand['id']}/positions",
                params={"expand": "assortment"}
            )
            
            if positions_data:
                for position in positions_data.get("rows", []):
                    assortment = position.get("assortment", {})
                    assortment_id = None

                    if isinstance(assortment, dict):
                        # –ü—Ä—è–º–æ–π id, –µ—Å–ª–∏ expand —Å—Ä–∞–±–æ—Ç–∞–ª
                        assortment_id = assortment.get("id")
                        if not assortment_id:
                            # –ü—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∏–∑ meta.href
                            href = (assortment.get("meta", {}) or {}).get("href", "")
                            if href:
                                assortment_id = href.rstrip("/").split("/")[-1]

                    if assortment_id == product_id:
                        sales_data.append({
                            "date": demand.get("moment"),
                            "quantity": position.get("quantity", 0),
                            "price": (position.get("price", 0) or 0) / 100,
                            "sum": (position.get("sum", 0) or 0) / 100
                        })
        
        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(sales_data)} –∑–∞–ø–∏—Å–µ–π –ø—Ä–æ–¥–∞–∂ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id}")
        return sales_data
    
    async def get_stock_data(self, product_code: str, days_back: int = 120) -> List[Dict]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö —Ç–æ–≤–∞—Ä–∞: day-by-day –ø–æ report/stock/all —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –∫–æ–¥—É."""
        logger.info(f"üì¶ –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö –¥–ª—è –∫–æ–¥–∞ {product_code}...")

        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days_back)

        stock_data: List[Dict] = []
        current = start_date
        while current <= end_date:
            params = {
                "moment": f"{current.isoformat()}T00:00:00",
                "limit": 1000,
            }

            data = await self._make_request(
                "GET",
                f"{self.api_url}/report/stock/all",
                params=params,
            )
            if data:
                for row in data.get("rows", []):
                    row_code = row.get("code")
                    if product_code and row_code and row_code != product_code:
                        continue
                    if product_code and not row_code:
                        # –ï—Å–ª–∏ —É —Å—Ç—Ä–æ–∫–∏ –Ω–µ—Ç –∫–æ–¥–∞, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º (–º—ã —Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å —Ç–æ–≤–∞—Ä–∞–º–∏ —Å –∫–æ–¥–æ–º)
                        continue
                    stock_data.append({
                        "date": current.isoformat(),
                        "quantity": row.get("quantity", 0),
                        "reserve": row.get("reserve", 0),
                        "inTransit": row.get("inTransit", 0),
                        "product_code": row_code or product_code,
                    })
            # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –¥–Ω—è–º–∏ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏
            await asyncio.sleep(0.2)
            current += timedelta(days=1)

        logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(stock_data)} –¥–Ω–µ–≤–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π –æ—Å—Ç–∞—Ç–∫–æ–≤ –¥–ª—è –∫–æ–¥–∞ {product_code}")
        return stock_data

class MLModelTrainer:
    """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è ML –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self):
        self.models_dir = "data/real_models"
        os.makedirs(self.models_dir, exist_ok=True)
    
    def prepare_features(self, sales_data: List[Dict], stock_data: List[Dict]) -> pd.DataFrame:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: –ø—Ä–æ–¥–∞–∂–∏ –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –∫–∞–∫ —É–±—ã–≤–∞–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤ (stock delta)."""
        # –§–æ—Ä–º–∏—Ä—É–µ–º DataFrame –æ—Å—Ç–∞—Ç–∫–æ–≤
        if not stock_data:
            return pd.DataFrame()

        sdf = pd.DataFrame(stock_data)
        if sdf.empty:
            return pd.DataFrame()
        sdf['date'] = pd.to_datetime(sdf['date'])
        sdf = sdf.sort_values('date').reset_index(drop=True)

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—Ç–æ–ª–±—Ü—ã
        for col in ['quantity', 'reserve', 'inTransit']:
            if col not in sdf.columns:
                sdf[col] = 0

        # –í—ã—á–∏—Å–ª—è–µ–º –¥–Ω–µ–≤–Ω—ã–µ –ø—Ä–æ–¥–∞–∂–∏ –∫–∞–∫ —É–±—ã–≤–∞–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤ (–±–µ–∑ —É—á–µ—Ç–∞ –ø–æ–ø–æ–ª–Ω–µ–Ω–∏–π)
        sdf['prev_stock'] = sdf['quantity'].shift(1).fillna(sdf['quantity'])
        raw_delta = sdf['prev_stock'] - sdf['quantity']
        sdf['daily_sales'] = raw_delta.clip(lower=0)

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏—Ç–æ–≥–æ–≤–æ–≥–æ DataFrame —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        sdf['year'] = sdf['date'].dt.year
        sdf['month'] = sdf['date'].dt.month
        sdf['day'] = sdf['date'].dt.day
        sdf['day_of_year'] = sdf['date'].dt.dayofyear
        sdf['day_of_week'] = sdf['date'].dt.dayofweek
        sdf['is_month_start'] = sdf['day'] == 1
        sdf['is_quarter_start'] = (sdf['day'] == 1) & (sdf['month'].isin([1, 4, 7, 10]))
        sdf['is_weekend'] = sdf['day_of_week'] >= 5
        sdf['is_holiday_season'] = sdf['month'].isin([12, 1, 2])
        sdf['is_summer_season'] = sdf['month'].isin([6, 7, 8])

        # –õ–∞–≥–∏ –∏ —Å–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ
        sdf['stock_lag_1'] = sdf['quantity'].shift(1).fillna(sdf['quantity'])
        sdf['sales_lag_1'] = sdf['daily_sales'].shift(1).fillna(0)
        sdf['sales_lag_7'] = sdf['daily_sales'].shift(7).fillna(0)
        sdf['sales_lag_30'] = sdf['daily_sales'].shift(30).fillna(0)
        sdf['sales_ma_7'] = sdf['daily_sales'].rolling(7, min_periods=1).mean()
        sdf['stock_ma_7'] = sdf['quantity'].rolling(7, min_periods=1).mean()

        # –ß–∏—Å—Ç–∏–º –æ—Ç NaN (–ø–æ—Å–ª–µ lag/rolling –æ—Å—Ç–∞–Ω—É—Ç—Å—è –ø–µ—Ä–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, –Ω–æ –º—ã –∏—Ö —É–∂–µ –∑–∞–ø–æ–ª–Ω–∏–ª–∏)
        sdf = sdf.fillna(0)

        # –£–Ω–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–∞–±–æ—Ä–∞ –∫–æ–ª–æ–Ω–æ–∫
        feature_df = sdf.rename(columns={'quantity': 'stock'})
        return feature_df
    
    def train_models(self, product_id: str, features_df: pd.DataFrame) -> Dict:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
        if len(features_df) < 20:  # –£–º–µ–Ω—å—à–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id}: {len(features_df)} –∑–∞–ø–∏—Å–µ–π")
            return {}
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        feature_columns = [col for col in features_df.columns if col not in ['daily_sales', 'date']]
        X = features_df[feature_columns].values
        y = features_df['daily_sales'].values
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
        models = {}
        
        # –õ–∏–Ω–µ–π–Ω–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è
        lr_model = LinearRegression()
        lr_model.fit(X_train_scaled, y_train)
        lr_score = lr_model.score(X_test_scaled, y_test)
        models['linear_regression'] = {
            'model': lr_model,
            'scaler': scaler,
            'accuracy': lr_score,
            'feature_columns': feature_columns
        }
        
        # –°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å
        rf_model = RandomForestRegressor(n_estimators=50, random_state=42)  # –£–º–µ–Ω—å—à–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ä–µ–≤—å–µ–≤
        rf_model.fit(X_train_scaled, y_train)
        rf_score = rf_model.score(X_test_scaled, y_test)
        models['random_forest'] = {
            'model': rf_model,
            'scaler': scaler,
            'accuracy': rf_score,
            'feature_columns': feature_columns
        }
        
        logger.info(f"‚úÖ –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id} –æ–±—É—á–µ–Ω—ã:")
        logger.info(f"  Linear Regression: {lr_score:.4f}")
        logger.info(f"  Random Forest: {rf_score:.4f}")
        
        return models

    def build_universal_models_file(self) -> int:
        """–°–æ–±–∏—Ä–∞–µ—Ç –µ–¥–∏–Ω—ã–π —Ñ–∞–π–ª /app/data/universal_forecast_models.pkl –∏–∑ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö real_models."""
        models_root = self.models_dir
        universal = {'models': {}, 'results': {}, 'features': [], 'training_date': datetime.now().isoformat(), 'model_type': 'real_data'}
        try:
            for name in os.listdir(models_root):
                if not name.endswith('_metadata.json'):
                    continue
                meta_path = os.path.join(models_root, name)
                with open(meta_path, 'r') as f:
                    meta = json.load(f)
                pid = meta.get('product_id')
                results = meta.get('results', {})
                models = meta.get('models', {})
                if not pid or not results or not models:
                    continue
                # –≤—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å —Å –ª—É—á—à–µ–π accuracy
                best = max(results.keys(), key=lambda k: results[k].get('accuracy', 0))
                model_path = models.get(best)
                if not model_path or not os.path.exists(model_path):
                    continue
                with open(model_path, 'rb') as f:
                    model_obj = pickle.load(f)
                # –ø—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å scaler —Ä—è–¥–æ–º
                scaler_path = model_path.replace('.pkl', '_scaler.pkl')
                scaler_obj = None
                if os.path.exists(scaler_path):
                    with open(scaler_path, 'rb') as f:
                        scaler_obj = pickle.load(f)
                universal['models'][pid] = model_obj
                universal['results'][pid] = {'metadata': {'chosen_model': best, **results[best]}, 'scaler': scaler_obj}
            out_path = '/app/data/universal_forecast_models.pkl'
            with open(out_path, 'wb') as f:
                pickle.dump(universal, f)
            return len(universal['models'])
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–±–æ—Ä–∫–∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–µ–π: {e}")
            return 0
    
    def save_models(self, product_id: str, models: Dict):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
        model_data = {
            'product_id': product_id,
            'models': {},
            'results': {},
            'features': [],
            'training_date': datetime.now().isoformat(),
            'model_type': 'real_data'
        }
        
        for model_name, model_info in models.items():
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
            model_path = os.path.join(self.models_dir, f"{product_id}_{model_name}.pkl")
            with open(model_path, 'wb') as f:
                pickle.dump(model_info['model'], f)
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º scaler
            scaler_path = os.path.join(self.models_dir, f"{product_id}_{model_name}_scaler.pkl")
            with open(scaler_path, 'wb') as f:
                pickle.dump(model_info['scaler'], f)
            
            model_data['models'][model_name] = model_path
            model_data['results'][model_name] = {
                'accuracy': model_info['accuracy'],
                'feature_columns': model_info['feature_columns']
            }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata_path = os.path.join(self.models_dir, f"{product_id}_metadata.json")
        with open(metadata_path, 'w') as f:
            json.dump(model_data, f, indent=2)
        
        logger.info(f"üíæ –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_id} —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {self.models_dir}")

async def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π —Å —É—á–µ—Ç–æ–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π API MoySklad")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    data_collector = RateLimitedMoySkladCollector()
    model_trainer = MLModelTrainer()
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤
    products = await data_collector.get_all_products()
    
    if not products:
        logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–≤–∞—Ä—ã –∏–∑ MoySklad")
        logger.info("üí° –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        logger.info("   - API –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –∏–∑-–∑–∞ –ø—Ä–µ–≤—ã—à–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤")
        logger.info("   - –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ç–æ–∫–µ–Ω API")
        logger.info("   - –ù–µ—Ç –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø–∞")
        return
    
    logger.info(f"üì¶ –ù–∞–π–¥–µ–Ω–æ {len(products)} —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
    
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    test_products = products[:3]  # –£–º–µ–Ω—å—à–∞–µ–º –¥–æ 3 —Ç–æ–≤–∞—Ä–æ–≤
    
    successful_models = 0
    
    for i, product in enumerate(test_products, 1):
        product_id = product['id']
        product_name = product.get('name', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä')
        product_code = product.get('code', '')
        
        logger.info(f"üì¶ [{i}/{len(test_products)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä: {product_name}")
        logger.info(f"   ID: {product_id}, –ö–æ–¥: {product_code}")
        
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –æ–± –æ—Å—Ç–∞—Ç–∫–∞—Ö
            stock_data = await data_collector.get_stock_data(product_id, days_back=120)

            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–ø—Ä–æ–¥–∞–∂–∏ = —É–±—ã–≤–∞–Ω–∏–µ –æ—Å—Ç–∞—Ç–∫–æ–≤)
            features_df = model_trainer.prepare_features([], stock_data)
            
            if features_df.empty:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_name}")
                continue
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            models = model_trainer.train_models(product_id, features_df)
            
            if models:
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
                model_trainer.save_models(product_id, models)
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_name} —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω—ã –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
                successful_models += 1
            else:
                logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ {product_name}")
        
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–≤–∞—Ä–∞ {product_name}: {e}")
            continue
        
        # –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–æ–≤–∞—Ä–∞–º–∏
        if i < len(test_products):
            logger.info("‚è≥ –ü–∞—É–∑–∞ –º–µ–∂–¥—É —Ç–æ–≤–∞—Ä–∞–º–∏ –¥–ª—è —Å–æ–±–ª—é–¥–µ–Ω–∏—è –ª–∏–º–∏—Ç–æ–≤ API...")
            await asyncio.sleep(5)
    
    logger.info(f"üéâ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –£—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: {successful_models}/{len(test_products)}")
    
    if successful_models > 0:
        # –°–±–æ—Ä–∫–∞ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–µ–π
        built = model_trainer.build_universal_models_file()
        logger.info(f"‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞. –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª –º–æ–¥–µ–ª–µ–π —Å–æ–±—Ä–∞–Ω, –º–æ–¥–µ–ª–µ–π: {built}")
    else:
        logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—É—á–∏—Ç—å –Ω–∏ –æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ API —Ç–æ–∫–µ–Ω –∏ –ª–∏–º–∏—Ç—ã.")

if __name__ == "__main__":
    asyncio.run(main()) 