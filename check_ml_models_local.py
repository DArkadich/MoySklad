#!/usr/bin/env python3
"""
–ü—Ä–æ–≤–µ—Ä–∫–∞ ML –º–æ–¥–µ–ª–µ–π –≤ –ª–æ–∫–∞–ª—å–Ω–æ–π —Å—Ä–µ–¥–µ
"""

import os
import pickle
import pandas as pd
import numpy as np
from datetime import datetime
import json

def check_model_files():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π"""
    print("üîç –ü–†–û–í–ï–†–ö–ê –§–ê–ô–õ–û–í ML-–ú–û–î–ï–õ–ï–ô")
    print("=" * 50)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    data_dirs = [
        "data/",
        "services/moysklad-service/data/"
    ]
    
    model_files = []
    csv_files = []
    
    for data_dir in data_dirs:
        if os.path.exists(data_dir):
            print(f"\nüìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {data_dir}")
            
            # –ò—â–µ–º —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π
            for filename in os.listdir(data_dir):
                filepath = os.path.join(data_dir, filename)
                if filename.endswith('.pkl') or filename.endswith('.joblib'):
                    model_files.append(filepath)
                    print(f"   ‚úÖ –ú–æ–¥–µ–ª—å: {filename}")
                elif filename.endswith('.csv'):
                    csv_files.append(filepath)
                    print(f"   üìä –î–∞–Ω–Ω—ã–µ: {filename}")
    
    return model_files, csv_files

def load_and_test_models(model_files):
    """–ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"""
    print(f"\nü§ñ –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –ú–û–î–ï–õ–ï–ô")
    print("=" * 50)
    
    models_info = []
    
    for model_file in model_files:
        try:
            print(f"\nüì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {os.path.basename(model_file)}")
            
            with open(model_file, 'rb') as f:
                model_data = pickle.load(f)
            
            print(f"   –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö: {type(model_data)}")
            
            if isinstance(model_data, dict):
                print(f"   –ö–ª—é—á–∏: {list(model_data.keys())}")
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
                for key, value in model_data.items():
                    if hasattr(value, 'predict'):
                        print(f"     {key}: ML –º–æ–¥–µ–ª—å (–º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∞)")
                    elif isinstance(value, (list, tuple)):
                        print(f"     {key}: —Å–ø–∏—Å–æ–∫/–∫–æ—Ä—Ç–µ–∂ –¥–ª–∏–Ω–æ–π {len(value)}")
                    elif isinstance(value, np.ndarray):
                        print(f"     {key}: numpy –º–∞—Å—Å–∏–≤ —Ñ–æ—Ä–º—ã {value.shape}")
                    else:
                        print(f"     {key}: {type(value).__name__}")
                
                models_info.append({
                    'file': model_file,
                    'type': 'dict',
                    'keys': list(model_data.keys()),
                    'has_ml_models': any(hasattr(v, 'predict') for v in model_data.values() if hasattr(v, '__iter__'))
                })
                
            elif hasattr(model_data, 'predict'):
                print(f"   ‚úÖ ML –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")
                print(f"   –ú–µ—Ç–æ–¥—ã: {[method for method in dir(model_data) if not method.startswith('_')]}")
                
                models_info.append({
                    'file': model_file,
                    'type': 'ml_model',
                    'ready': True
                })
                
            else:
                print(f"   ‚ö†Ô∏è –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö")
                models_info.append({
                    'file': model_file,
                    'type': 'unknown',
                    'ready': False
                })
                
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            models_info.append({
                'file': model_file,
                'error': str(e)
            })
    
    return models_info

def check_performance_data(csv_files):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π"""
    print(f"\nüìä –ü–†–û–í–ï–†–ö–ê –î–ê–ù–ù–´–• –û –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò")
    print("=" * 50)
    
    performance_data = {}
    
    for csv_file in csv_files:
        if 'performance' in csv_file.lower() or 'accuracy' in csv_file.lower():
            try:
                print(f"\nüìà –§–∞–π–ª –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {os.path.basename(csv_file)}")
                
                df = pd.read_csv(csv_file)
                print(f"   –†–∞–∑–º–µ—Ä: {df.shape}")
                print(f"   –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
                
                if not df.empty:
                    print(f"   –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏:")
                    print(df.head().to_string())
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏
                    if 'accuracy' in df.columns or 'r2' in df.columns:
                        accuracy_col = 'accuracy' if 'accuracy' in df.columns else 'r2'
                        if accuracy_col in df.columns:
                            avg_accuracy = df[accuracy_col].mean()
                            print(f"   –°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å ({accuracy_col}): {avg_accuracy:.4f}")
                    
                    if 'mae' in df.columns:
                        avg_mae = df['mae'].mean()
                        print(f"   –°—Ä–µ–¥–Ω—è—è MAE: {avg_mae:.4f}")
                
                performance_data[os.path.basename(csv_file)] = {
                    'shape': df.shape,
                    'columns': list(df.columns),
                    'data': df.to_dict('records') if not df.empty else []
                }
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {e}")
    
    return performance_data

def check_stock_data(csv_files):
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞–Ω–Ω—ã—Ö –æ –∑–∞–ø–∞—Å–∞—Ö"""
    print(f"\nüì¶ –ü–†–û–í–ï–†–ö–ê –î–ê–ù–ù–´–• –û –ó–ê–ü–ê–°–ê–•")
    print("=" * 50)
    
    stock_data = {}
    
    for csv_file in csv_files:
        if 'stock' in csv_file.lower():
            try:
                print(f"\nüè≠ –§–∞–π–ª –∑–∞–ø–∞—Å–æ–≤: {os.path.basename(csv_file)}")
                
                df = pd.read_csv(csv_file)
                print(f"   –†–∞–∑–º–µ—Ä: {df.shape}")
                print(f"   –ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
                
                if not df.empty:
                    print(f"   –ü–µ—Ä–≤—ã–µ —Å—Ç—Ä–æ–∫–∏:")
                    print(df.head().to_string())
                    
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
                    if 'product_code' in df.columns:
                        unique_products = df['product_code'].nunique()
                        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø—Ä–æ–¥—É–∫—Ç–æ–≤: {unique_products}")
                    
                    if 'stock' in df.columns:
                        total_stock = df['stock'].sum()
                        avg_stock = df['stock'].mean()
                        print(f"   –û–±—â–∏–π –∑–∞–ø–∞—Å: {total_stock:.2f}")
                        print(f"   –°—Ä–µ–¥–Ω–∏–π –∑–∞–ø–∞—Å: {avg_stock:.2f}")
                
                stock_data[os.path.basename(csv_file)] = {
                    'shape': df.shape,
                    'columns': list(df.columns),
                    'data': df.to_dict('records') if not df.empty else []
                }
                
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è: {e}")
    
    return stock_data

def generate_summary_report(models_info, performance_data, stock_data):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞"""
    print(f"\nüìã –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢")
    print("=" * 50)
    
    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    total_models = len([m for m in models_info if m.get('ready', False)])
    total_files = len(models_info)
    ready_models = len([m for m in models_info if m.get('ready', False)])
    
    print(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π: {total_files}")
    print(f"   –ì–æ—Ç–æ–≤—ã—Ö ML –º–æ–¥–µ–ª–µ–π: {ready_models}")
    print(f"   –§–∞–π–ª–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {len(performance_data)}")
    print(f"   –§–∞–π–ª–æ–≤ –∑–∞–ø–∞—Å–æ–≤: {len(stock_data)}")
    
    # –û—Ü–µ–Ω–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏
    if ready_models > 0:
        print(f"\n‚úÖ ML –ú–û–î–ï–õ–ò –ì–û–¢–û–í–´ –ö –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Æ")
        print(f"   ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ {ready_models} –≥–æ—Ç–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π")
        print(f"   ‚Ä¢ –ú–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
        
        if performance_data:
            print(f"   ‚Ä¢ –ï—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π")
        
        if stock_data:
            print(f"   ‚Ä¢ –ï—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –æ –∑–∞–ø–∞—Å–∞—Ö –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞–Ω–∏—è")
            
    elif total_files > 0:
        print(f"\n‚ö†Ô∏è –ú–û–î–ï–õ–ò –ù–ê–ô–î–ï–ù–´, –ù–û –¢–†–ï–ë–£–Æ–¢ –ü–†–û–í–ï–†–ö–ò")
        print(f"   ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ {total_files} —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–µ–π")
        print(f"   ‚Ä¢ –ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö")
        
    else:
        print(f"\n‚ùå ML –ú–û–î–ï–õ–ò –ù–ï –ù–ê–ô–î–ï–ù–´")
        print(f"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: data/, services/moysklad-service/data/")
        print(f"   ‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª–∏ –±—ã–ª–∏ –æ–±—É—á–µ–Ω—ã")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
    report = {
        'timestamp': datetime.now().isoformat(),
        'summary': {
            'total_model_files': total_files,
            'ready_models': ready_models,
            'performance_files': len(performance_data),
            'stock_files': len(stock_data)
        },
        'models_info': models_info,
        'performance_data': performance_data,
        'stock_data': stock_data
    }
    
    with open('ml_models_local_check.json', 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"\nüíæ –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: ml_models_local_check.json")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üîç –ü–†–û–í–ï–†–ö–ê ML-–ú–û–î–ï–õ–ï–ô –í –õ–û–ö–ê–õ–¨–ù–û–ô –°–†–ï–î–ï")
    print("=" * 60)
    print(f"üìÖ –í—Ä–µ–º—è –ø—Ä–æ–≤–µ—Ä–∫–∏: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π
    model_files, csv_files = check_model_files()
    
    if not model_files:
        print("\n‚ùå –§–∞–π–ª—ã –º–æ–¥–µ–ª–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω—ã!")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:")
        print("   - data/")
        print("   - services/moysklad-service/data/")
        return
    
    # 2. –¢–µ—Å—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏
    models_info = load_and_test_models(model_files)
    
    # 3. –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    performance_data = check_performance_data(csv_files)
    
    # 4. –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–∞–Ω–Ω—ã–µ –æ –∑–∞–ø–∞—Å–∞—Ö
    stock_data = check_stock_data(csv_files)
    
    # 5. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    generate_summary_report(models_info, performance_data, stock_data)

if __name__ == "__main__":
    main()
